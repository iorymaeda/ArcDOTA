{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a948b652-726a-42cc-99d6-83465d01d573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys; sys.path.append('../')\n",
    "import yaml\n",
    "import pickle\n",
    "import datetime\n",
    "from contextlib import suppress\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d042872f-26eb-4e94-92f7-a793827a2732",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../configs/train.yaml', 'r') as stream:\n",
    "    config = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c173a5cd-741c-44c8-a554-793f37424e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_size = config['split']['league']['val']\n",
    "t_size = config['split']['league']['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77df194b-1488-4ffd-a583-bf8f3fd54570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22299\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_json(f'../parse/output/league/train_df.json')\n",
    "print(len(train_df))\n",
    "\n",
    "if v_size > 0:\n",
    "    val_df = pd.read_json(f'../parse/output/league/val_df.json')\n",
    "    print(len(val_df))\n",
    "if t_size > 0:\n",
    "    test_df = pd.read_json(f'../parse/output/league/test_df.json')\n",
    "    print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bf21682-ad12-419c-a434-432e1f82f30e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 22299/22299 [04:51<00:00, 76.42it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df['part'] = 'train'\n",
    "if v_size > 0: val_df['part'] = 'val'\n",
    "if t_size > 0: test_df['part'] = 'test'\n",
    "\n",
    "for eval_ in [True, ]:\n",
    "    corpus = train_df.reset_index(drop=True)\n",
    "    train_dataset = utils.nn.datasets.LeagueDataset(\n",
    "        corpus=corpus, \n",
    "        evaluate_tokenize=eval_,\n",
    "        indexes=corpus.index[(corpus['part'] == 'train')], \n",
    "        y_output='crossentropy',\n",
    "    ).build()\n",
    "    with open(f'output/train_cache{\"_evaluated\" if eval_ else \"\"}.pkl', 'wb') as p:\n",
    "        pickle.dump(train_dataset.cache, p)\n",
    "\n",
    "        \n",
    "    if v_size > 0:\n",
    "        corpus = pd.concat([corpus, val_df]).reset_index(drop=True)\n",
    "        val_dataset = utils.nn.datasets.LeagueDataset(\n",
    "            corpus=corpus, \n",
    "            evaluate_tokenize=eval_,\n",
    "            indexes=corpus.index[(corpus['part'] == 'val')], \n",
    "            y_output='crossentropy',\n",
    "        ).build()\n",
    "        with open(f'output/val_cache{\"_evaluated\" if eval_ else \"\"}.pkl', 'wb') as p:\n",
    "            pickle.dump(val_dataset.cache, p)\n",
    "        \n",
    "    if t_size > 0:\n",
    "        corpus = pd.concat([corpus, test_df]).reset_index(drop=True)\n",
    "        test_dataset = utils.nn.datasets.LeagueDataset(\n",
    "            corpus=corpus, \n",
    "            evaluate_tokenize=eval_,\n",
    "            indexes=corpus.index[(corpus['part'] == 'test')], \n",
    "            y_output='crossentropy',\n",
    "        ).build()\n",
    "        with open(f'output/test_cache{\"_evaluated\" if eval_ else \"\"}.pkl', 'wb') as p:\n",
    "            pickle.dump(test_dataset.cache, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65c8bb0c-2586-43bf-b702-8e15946cffca",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "batch_size = config['batch_size']['league']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c1eb92b-8ea4-4ec7-a0fd-e081cac47a3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14843\n"
     ]
    }
   ],
   "source": [
    "train_dataset = utils.nn.datasets.LeagueDataset(\n",
    "    corpus=None, \n",
    "    indexes=None, \n",
    "    y_output='crossentropy')\n",
    "train_dataset.cache = pickle.load(open('output/train_cache_evaluated.pkl', 'rb'))\n",
    "train_dataset.build()\n",
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size']['league'], shuffle=False, num_workers=0)\n",
    "print(len(train_dataset))\n",
    "\n",
    "if v_size > 0:\n",
    "    val_dataset = utils.nn.datasets.LeagueDataset(\n",
    "        corpus=None, \n",
    "        indexes=None, \n",
    "        y_output='crossentropy')\n",
    "    val_dataset.cache = pickle.load(open('output/val_cache_evaluated.pkl', 'rb'))\n",
    "    val_dataset.build()\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config['batch_size']['league'], shuffle=False, num_workers=0)\n",
    "    print(len(val_dataset))\n",
    "    \n",
    "if t_size > 0:\n",
    "    test_dataset = utils.nn.datasets.LeagueDataset(\n",
    "        corpus=None, \n",
    "        indexes=None, \n",
    "        y_output='crossentropy')\n",
    "    test_dataset.cache = pickle.load(open('output/test_cache_evaluated.pkl', 'rb'))\n",
    "    test_dataset.build()\n",
    "    test_loader = DataLoader(test_dataset, batch_size=config['batch_size']['league'], shuffle=False, num_workers=0)\n",
    "    print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45df1b50-a27c-4f09-adfb-326b294a0676",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Embedding: 1-1                         968\n",
      "├─WindowedGamesFeatureEncoder: 1-2       --\n",
      "|    └─StatsEncoder: 2-1                 --\n",
      "|    |    └─Linear: 3-1                  800\n",
      "|    |    └─Linear: 3-2                  800\n",
      "|    |    └─ModuleList: 3-3              960\n",
      "|    └─ResultEncoder: 2-2                --\n",
      "|    |    └─Embedding: 3-4               64\n",
      "|    └─Embedding: 2-3                    1,056\n",
      "├─RNN: 1-3                               --\n",
      "|    └─GRU: 2-4                          25,344\n",
      "├─OutputHead: 1-4                        --\n",
      "|    └─Sequential: 2-5                   --\n",
      "|    |    └─Linear: 3-5                  1,152\n",
      "|    |    └─GELU: 3-6                    --\n",
      "|    |    └─Dropout: 3-7                 --\n",
      "|    |    └─Linear: 3-8                  768\n",
      "|    |    └─GELU: 3-9                    --\n",
      "|    |    └─Dropout: 3-10                --\n",
      "|    └─Sequential: 2-6                   --\n",
      "|    |    └─Linear: 3-11                 1,536\n",
      "|    |    └─GELU: 3-12                   --\n",
      "|    |    └─Dropout: 3-13                --\n",
      "|    |    └─Linear: 3-14                 512\n",
      "|    |    └─GELU: 3-15                   --\n",
      "|    |    └─Dropout: 3-16                --\n",
      "|    |    └─Linear: 3-17                 32\n",
      "=================================================================\n",
      "Total params: 33,992\n",
      "Trainable params: 33,992\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "def get_writer(name:str):\n",
    "    log_dir = f\"logs/fit/prematch/{name}\"\n",
    "    writer = SummaryWriter(log_dir)\n",
    "    return writer\n",
    "\n",
    "def compute_metrics(y_pred, y_true):\n",
    "    return {\n",
    "        'Acc': float(torchmetrics.functional.accuracy(y_pred, y_true)),\n",
    "        'AUC': float(torchmetrics.functional.auroc(y_pred, y_true)),\n",
    "        'MAP': float(torchmetrics.functional.average_precision(y_pred, y_true)),\n",
    "        'LogLoss': metrics.log_loss(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "tokenizer = utils.tokenizer.Tokenizer(path=\"../parse/output/tokenizer_league.pkl\")\n",
    "\n",
    "utils.nn.PrematchModel(\n",
    "    teams_num=max(tokenizer.teams_vocab.values()),\n",
    "    regression=False,\n",
    ").summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce92128d-8572-4e8a-ad02-055964a1e029",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\royta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\royta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "results = []\n",
    "models_names = []\n",
    "\n",
    "date = datetime.datetime.now().strftime(\"%Y.%m.%d - %H-%M\")\n",
    "for n in range(5):    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    name = f'Ensemble {n} {date}'\n",
    "    writer = get_writer(name)\n",
    "\n",
    "    model = utils.nn.PrematchModel(\n",
    "        teams_num=max(tokenizer.teams_vocab.values()),\n",
    "        regression=False,\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.2)\n",
    "    scheduler = utils.nn.shedulers.TransformerLRScheduler(\n",
    "        optimizer=optimizer,\n",
    "        init_lr=1e-5,\n",
    "        peak_lr=1e-3,\n",
    "        final_lr=1e-5,\n",
    "        final_lr_scale=0.01,\n",
    "        warmup_steps=10,\n",
    "        decay_steps=70,\n",
    "    )\n",
    "\n",
    "    trainer = utils.nn.trainers.PremtachTrainer(\n",
    "        model=model, \n",
    "        loss_fn=torch.nn.CrossEntropyLoss(), \n",
    "        sheduler=scheduler,\n",
    "        optimizer=optimizer,\n",
    "        metric={\n",
    "            \"Acc\": torchmetrics.Accuracy(num_classes=2),\n",
    "            \"AUC\": torchmetrics.AUROC(num_classes=2),\n",
    "            \"MAP\": torchmetrics.AveragePrecision(num_classes=2),\n",
    "        },\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # --------------------------------------------------------- #\n",
    "    wait = 0\n",
    "    patience = 50\n",
    "\n",
    "    epoch = 0\n",
    "    best_loss = -np.inf\n",
    "\n",
    "    with suppress(KeyboardInterrupt):\n",
    "        while epoch < 80:\n",
    "            # --------------------------------------------- #\n",
    "            # Train\n",
    "            train_loss = trainer.train_epoch(train_loader)\n",
    "            writer.add_scalar('LogLoss/train', train_loss, epoch)\n",
    "            writer.add_scalar('Acc/train', trainer.metric['Acc'].compute(), epoch)\n",
    "            writer.add_scalar('AUC/train', trainer.metric['AUC'].compute(), epoch)\n",
    "            writer.add_scalar('MAP/train', trainer.metric['MAP'].compute(), epoch)\n",
    "            \n",
    "            # --------------------------------------------- #\n",
    "            # Val\n",
    "            if v_size > 0:\n",
    "                val_pred, val_true = trainer.predict(val_loader)\n",
    "                val_pred = val_pred.softmax(dim=1)[:, 1]\n",
    "                val_metrics = compute_metrics(val_pred, val_true)\n",
    "                for _metric in val_metrics:\n",
    "                    writer.add_scalar(f'{_metric}/val', val_metrics[_metric], epoch)\n",
    "                \n",
    "            # --------------------------------------------- #\n",
    "            # Test    \n",
    "            if t_size > 0:\n",
    "                test_pred, test_true = trainer.predict(test_loader)\n",
    "                test_pred = test_pred.softmax(dim=1)[:, 1]\n",
    "                test_metrics = compute_metrics(test_pred, test_true)\n",
    "                for _metric in test_metrics:\n",
    "                    writer.add_scalar(f'{_metric}/test', test_metrics[_metric], epoch)\n",
    "                \n",
    "            # --------------------------------------------- #\n",
    "            # EarlyStopping\n",
    "            wait, epoch = wait+1, epoch+1\n",
    "            # if val_metrics['AUC'] > best_loss:\n",
    "                # torch.save(trainer.checkpoint(), f'output/models_w/prematch/{name}.torch')\n",
    "                # best_loss = val_metrics['AUC']\n",
    "                # wait = 0\n",
    "        checkpoint = trainer.checkpoint()\n",
    "        checkpoint['kwargs'] = {\n",
    "            'teams_num': max(tokenizer.teams_vocab.values()), \n",
    "            'regression': False,\n",
    "        }\n",
    "        torch.save(checkpoint, f'output/models_w/prematch/{name}.torch')\n",
    "        \n",
    "    models_names.append(name)\n",
    "    # --------------------------------------------- #\n",
    "    # Load and evaluate\n",
    "    if t_size > 0 or v_size > 0:\n",
    "    \n",
    "        checkpoint = torch.load(f'output/models_w/prematch/{name}.torch')\n",
    "        trainer.model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "        test_pred, test_true = trainer.predict(test_loader if t_size > 0 else val_loader)\n",
    "        test_pred = test_pred.softmax(dim=1)[:, 1]\n",
    "\n",
    "        test_metrics = compute_metrics(test_pred, test_true)\n",
    "        test_metrics['epoch'] = epoch\n",
    "\n",
    "        preds.append(test_pred)\n",
    "        results.append(test_metrics)\n",
    "        \n",
    "    \n",
    "if t_size > 0 or v_size > 0:\n",
    "    preds = torch.vstack(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94888e36-28c1-4ddf-a586-368b98123c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ensemble 0 2022.09.14 - 21-59']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c1ac8fb5-9117-45c7-a405-10ad4ae690a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_names = [\n",
    "    'Ensemble 0 2022.09.14 - 21-46',\n",
    "    'Ensemble 1 2022.09.14 - 21-46',\n",
    "    'Ensemble 2 2022.09.14 - 21-46',\n",
    "    'Ensemble 3 2022.09.14 - 21-46',\n",
    "    'Ensemble 4 2022.09.14 - 21-46',\n",
    "    'Ensemble 0 2022.09.14 - 21-59'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5462b94d-5894-4f27-8a39-dfcd210745f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "results = []\n",
    "for name in models_names:\n",
    "    checkpoint = torch.load(f'output/models_w/prematch/{name}.torch')\n",
    "    trainer.model.load_state_dict(checkpoint['model'])\n",
    "        \n",
    "    pred, true = trainer.predict(train_loader)\n",
    "    pred = pred.softmax(dim=1)[:, 1]\n",
    "\n",
    "    preds.append(pred)\n",
    "    results.append(compute_metrics(pred, true))\n",
    "    \n",
    "preds = torch.vstack(preds)\n",
    "ensemble_mean_pred = preds.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6450d6ea-ab49-4820-a675-dfffe8681403",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_num = preds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "01999289-5c43-484e-9017-7e2b6bf20fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0459, 0.0465, 0.0450, 0.0456, 0.0475, 0.1120])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds - ensemble_mean_pred).std(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2317ff0a-b941-48de-abdf-86c9edea83e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0658, 0.0663, 0.0648, 0.0655, 0.0668, 0.1169])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.vstack([(preds[n] - preds).std(dim=1) for n in range(models_num)]).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c2494c9-9caa-490b-9078-db2401754185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4993, 0.5597, 0.5439,  ..., 0.4772, 0.3861, 0.6793])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "450be96d-a9a7-4c7f-9942-a5ed8798b1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5440, 0.5614, 0.5854,  ..., 0.4954, 0.3792, 0.6384])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_mean_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e6dd9dd-dc7c-4acc-bdd0-2b9fb985e1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Acc': 0.6323519349098206,\n",
       " 'AUC': 0.6847135424613953,\n",
       " 'MAP': 0.6849225759506226,\n",
       " 'LogLoss': 0.638383864683318}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(ensemble_mean_pred, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c397623-ecef-4924-81ae-22c5fd214321",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "results = []\n",
    "for name in models_names:\n",
    "    checkpoint = torch.load(f'output/models_w/prematch/{name}.torch')\n",
    "    trainer.model.load_state_dict(checkpoint['model'])\n",
    "        \n",
    "    pred, true = trainer.predict(test_loader)\n",
    "    pred = pred.softmax(dim=1)[:, 1]\n",
    "\n",
    "    preds.append(pred)\n",
    "    results.append(compute_metrics(pred, true))\n",
    "    \n",
    "preds = torch.vstack(preds)\n",
    "ensemble_mean_pred = preds.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "136fab30-7929-4317-aa89-5caf8661af24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Acc': 0.5718358159065247,\n",
       " 'AUC': 0.6068392992019653,\n",
       " 'MAP': 0.6015220284461975,\n",
       " 'LogLoss': 0.6759956551454495}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(ensemble_mean_pred, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f025eb-1ef7-47d5-b77b-c20b90663950",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preds.std(dim=0)[:, None].numpy()\n",
    "Y = (ensemble_mean_pred.round() != true).numpy().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa51abe-e462-4f6e-ab69-e94e2dd5d6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y, random_state=69, train_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f37298-abd3-4e92-899e-0b9fe2f89a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13137, 1)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecdbaae-d83e-415c-a2b0-2503bc77b000",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "xtrain, ytrain = smote.fit_resample(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61242c0e-b16e-4688-8a9f-fc07ffd31c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16548, 1)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "d5d0ace2-a3d0-404a-878c-08b491deed7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Acc': 0.516438364982605,\n",
       " 'AUC': 0.4909028708934784,\n",
       " 'MAP': 0.35196858644485474,\n",
       " 'LogLoss': 0.6933551910620996}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression().fit(xtrain, ytrain)\n",
    "pred = clf.predict_proba(xtest)\n",
    "\n",
    "compute_metrics(torch.from_numpy(pred[:, 1]), torch.from_numpy(ytest.astype('int32')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "22a434bc-06cc-4ef6-a1a6-1b399d4e029b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Acc': 0.5109589099884033,\n",
       " 'AUC': 0.4926212430000305,\n",
       " 'MAP': 0.3605821132659912,\n",
       " 'LogLoss': 16.614337861865202}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state=0).fit(xtrain, ytrain)\n",
    "pred = clf.predict_proba(xtest)\n",
    "\n",
    "compute_metrics(torch.from_numpy(pred[:, 1]), torch.from_numpy(ytest.astype('int32')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02ca1139-ef50-4bea-90eb-b9d86877e46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "stride = 32\n",
    "\n",
    "to_plot = {\n",
    "    'Acc': [],\n",
    "    'AUC': [],\n",
    "    'MAP': [],\n",
    "    'LogLoss': [],\n",
    "}\n",
    "for batch in range(0, len(true)-batch_size, stride):\n",
    "    _m = compute_metrics(ensemble_mean_pred[batch:batch+batch_size], true[batch:batch+batch_size])\n",
    "    \n",
    "    for key in _m: to_plot[key].append(_m[key])\n",
    "    \n",
    "del to_plot['LogLoss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be7520f-917f-445f-88d0-eda0dee74ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in to_plot:\n",
    "    plt.plot(to_plot[k])\n",
    "\n",
    "plt.legend(to_plot.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390d6369-f5fc-443a-b96d-8f628873226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "\n",
    "ax.set_title(\"Calibration curve\")\n",
    "display = CalibrationDisplay.from_predictions(\n",
    "    true,\n",
    "    ensemble_mean_pred, \n",
    "    n_bins=10,\n",
    "    name=\"Ensembling models\",\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "\n",
    "major_ticks = np.arange(0, 1+1e-6, 0.1)\n",
    "minor_ticks = np.arange(0, 1+1e-6, 0.025)\n",
    "\n",
    "ax.set_xticks(major_ticks)\n",
    "ax.set_xticks(minor_ticks, minor=True)\n",
    "ax.set_yticks(major_ticks)\n",
    "ax.set_yticks(minor_ticks, minor=True)\n",
    "\n",
    "ax.grid(which='minor', alpha=0.2)\n",
    "ax.grid(which='major', alpha=0.5)\n",
    "\n",
    "\n",
    "_ax = ax.twinx()\n",
    "sns.distplot(ensemble_mean_pred, ax=_ax, color='orange', hist=True, kde=False, rug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63890794-a960-424d-9d45-81afc53f8159",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8527ea9f-0db1-46ca-81d2-07bd8a379ac8",
   "metadata": {},
   "source": [
    "### Evaluate against book odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75ef0cc5-5fa6-4318-87e3-12577b8ad870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My metrics\n",
      "{'Acc': 0.5856443643569946, 'AUC': 0.6177918314933777, 'MAP': 0.6079134345054626, 'LogLoss': 0.6711387628443284}\n",
      "Book metrics\n",
      "{'Acc': 0.5481239557266235, 'AUC': 0.5502524375915527, 'MAP': 0.5543672442436218, 'LogLoss': 0.6985431941648487}\n"
     ]
    }
   ],
   "source": [
    "odds = pd.read_csv(\"../odds.csv\")\n",
    "\n",
    "M = (1/odds['radiant_odd'] + 1/odds['dire_odd']) - 1\n",
    "\n",
    "odds['r_pred'] = (1-M)/odds['radiant_odd']\n",
    "odds['d_pred'] = (1-M)/odds['dire_odd']\n",
    "\n",
    "# odds = odds[odds['match_id'] > 6000000000]\n",
    "\n",
    "compute_metrics(\n",
    "    y_pred=torch.from_numpy(1/odds['radiant_odd'].values), \n",
    "    y_true=torch.from_numpy(odds['radiant_win'].values.astype('int64'))\n",
    ")\n",
    "\n",
    "true = []\n",
    "my_pred = []\n",
    "book_pred = []\n",
    "\n",
    "_, test_true = trainer.predict(test_loader)\n",
    "for idx, batch in enumerate(DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)):\n",
    "    # if idx == 200: break\n",
    "    match_id = batch['match_id'].item()\n",
    "\n",
    "    if (odds['match_id'] == match_id).any():\n",
    "        true.append( test_true[idx].item() )\n",
    "        my_pred.append( ensemble_mean_pred[idx].item() )\n",
    "        book_pred.append( odds[odds['match_id'] == match_id]['r_pred'].values[0] )\n",
    "        \n",
    "true = torch.IntTensor(true)\n",
    "my_pred = torch.Tensor(my_pred)\n",
    "book_pred = torch.Tensor(book_pred)\n",
    "\n",
    "print(\"My metrics\")\n",
    "print(compute_metrics(my_pred, true))\n",
    "\n",
    "print(\"Book metrics\")\n",
    "print(compute_metrics(book_pred, true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5310e49c-ca75-4582-b3d1-db1f914563b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5027, 0.3681, 0.5266, 0.3381, 0.4116, 0.4513, 0.4528, 0.4322])\n",
      "tensor([0.4849, 0.3665, 0.5477, 0.3206, 0.4370, 0.4182, 0.4178, 0.3975])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for idx, batch in enumerate(DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=0)):\n",
    "    break\n",
    "\n",
    "batch = utils.nn.tools.batch_to_device(batch, 'cuda')\n",
    "with torch.no_grad():\n",
    "    out = model(batch)\n",
    "    print(out.softmax(dim=1)[:, 1].cpu())\n",
    "    \n",
    "    \n",
    "    batch['d_window'], batch['r_window'] = batch['r_window'], batch['d_window']\n",
    "    batch['teams']['radiant'], batch['teams']['dire'] = batch['teams']['dire'], batch['teams']['radiant']\n",
    "\n",
    "    out = model(batch)\n",
    "    print(out.softmax(dim=1)[:, 0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d9d21461-c67e-4940-bba4-8819a4a5bc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# odds = pd.concat([pd.read_json(\"../scarpe/output/odds1.json\"), pd.read_json(\"../scarpe/output/odds2.json\")])\n",
    "# odds = pd.read_json(\"../scarpe/output/odds1.json\")\n",
    "# odds = odds.drop_duplicates('match_id').reset_index()\n",
    "\n",
    "# true = []\n",
    "# my_pred = []\n",
    "# book_pred = []\n",
    "\n",
    "# _, test_true = trainer.predict(test_loader)\n",
    "# for idx, batch in enumerate(DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)):\n",
    "#     # if idx == 200: break\n",
    "#     match_id = batch['match_id'].item()\n",
    "\n",
    "#     if (odds['match_id'] == match_id).any():\n",
    "#         true.append( test_true[idx].item() )\n",
    "#         my_pred.append( ensemble_mean_pred[idx].item() )\n",
    "#         book_pred.append( 1/odds[odds['match_id'] == match_id]['r_odd'].values[0] )\n",
    "        \n",
    "# true = torch.IntTensor(true)\n",
    "# my_pred = torch.Tensor(my_pred)\n",
    "# book_pred = torch.Tensor(book_pred)\n",
    "\n",
    "# print(\"My metrics\")\n",
    "# print(compute_metrics(my_pred, true))\n",
    "\n",
    "# print(\"Book metrics\")\n",
    "# print(compute_metrics(book_pred, true))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb80e854-e3e1-4816-87c2-d4c12f1d248a",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff6bb2a-6018-48b2-8fe8-1503822e36a5",
   "metadata": {},
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "f7f911da-6e8a-499c-810b-6a23883016e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "team1 = tokenizer.teams_vocab[7119388]\n",
    "team2 = tokenizer.teams_vocab[15]\n",
    "\n",
    "batches = []\n",
    "for batch in train_loader:\n",
    "    b = ((batch['teams']['dire'] == team1) & (batch['teams']['radiant'] == team2)) | ((batch['teams']['dire'] == team2) & (batch['teams']['radiant'] == team1))\n",
    "    if b.any():\n",
    "        batches.append([batch, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "7ae359cf-fde1-4846-a1a1-8542d994a1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 5)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team1, team2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "6edaf0b4-387e-4feb-afa3-0ff9bc60935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batches[-1]\n",
    "batch, b = batch\n",
    "model.eval()\n",
    "output = model(utils.nn.tools.batch_to_device(batch, 'cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "cbc9d680-d94d-479b-a61b-7373c7025356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6676393091],\n",
       "        [6676488286],\n",
       "        [6705859209],\n",
       "        [6705943008],\n",
       "        [6707542480],\n",
       "        [6707633683],\n",
       "        [6707714718],\n",
       "        [6707754788]], device='cuda:0')"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['match_id'][b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "0e545a42-cbfe-4f5c-b0e9-b91c2ea91ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 23,  5,  5,  5, 23, 23, 23], device='cuda:0')"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['teams']['radiant'][b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "52b5a096-d9e6-46ec-90e7-108678bdc6b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([23,  5, 23, 23, 23,  5,  5,  5], device='cuda:0')"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['teams']['dire'][b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "dd1352a0-3319-4fc7-8505-fd4a3c86a273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['y'][b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "3ceb7147-7701-4460-8bf9-4cc73ff18bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7575, 0.2747, 0.5085, 0.6143, 0.5651, 0.4083, 0.4610, 0.4550],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[b].softmax(dim=1)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "1770d2f3-22d6-427e-a506-3538b79fabdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['match_id', 'r_window', 'd_window', 'y', 'y_r_stats', 'y_d_stats', 'teams'])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "2b6dd4ac-392b-4c5a-ba6b-df0972aa569d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_account_id</th>\n",
       "      <th>1_account_id</th>\n",
       "      <th>2_account_id</th>\n",
       "      <th>3_account_id</th>\n",
       "      <th>4_account_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22019</th>\n",
       "      <td>898754153</td>\n",
       "      <td>173978074</td>\n",
       "      <td>118134220</td>\n",
       "      <td>157475523</td>\n",
       "      <td>111114687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0_account_id  1_account_id  2_account_id  3_account_id  4_account_id\n",
       "22019     898754153     173978074     118134220     157475523     111114687"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['match_id'] == 6705859209][[f\"{s}_account_id\" for s in utils.base.ConfigBase.RADIANT_SIDE]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fbfae1-6024-413c-b95b-65766ab42009",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
