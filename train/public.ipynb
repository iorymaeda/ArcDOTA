{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "60da1f18-5b93-4a67-b68b-ff3b60aa6938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys; sys.path.append('../')\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib; matplotlib.style.use('seaborn')\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import utils\n",
    "\n",
    "\n",
    "RADIANT_SIDE = [0, 1, 2, 3, 4]\n",
    "DIRE_SIDE = [128, 129, 130, 131, 132]\n",
    "FEATURES = utils._typing.property.FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f99a925-5b4b-47d0-93dc-3a0bc055eef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_json(f'../parse/output/public/train_df.json')\n",
    "val_df = pd.read_json(f'../parse/output/public/val_df.json')\n",
    "test_df = pd.read_json(f'../parse/output/public/test_df.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71d90069-2a30-4626-9cbf-e6d9de158139",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(train_df)\n",
    "val_size = len(val_df)\n",
    "test_size = len(test_df)\n",
    "\n",
    "df = pd.concat([train_df, val_df, test_df], axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8b54c0d-4a22-45fa-95be-46b4e4acc192",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(r'../scarpe/dotaconstants/build/hero_names.json', 'r') as f:\n",
    "    hero_json = json.load(f)\n",
    "\n",
    "id_to_hero = {hero_json[npc]['id']: hero_json[npc]['localized_name'] for npc in hero_json}\n",
    "id_to_hero[0] = 'SPECIAL TOKEN'\n",
    "\n",
    "players_regression_columns = [f'{_}_{f}' for _ in RADIANT_SIDE + DIRE_SIDE for f in FEATURES]\n",
    "teams_regression_columns = [f'{_}_{f}' for _ in 'rd' for f in FEATURES]\n",
    "\n",
    "p_columns = [f'{_}_account_id' for _ in RADIANT_SIDE + DIRE_SIDE]\n",
    "h_columns = [f'{_}_hero_id' for _ in RADIANT_SIDE + DIRE_SIDE]\n",
    "r_columns = [f'{_}_hero_role' for _ in RADIANT_SIDE + DIRE_SIDE]\n",
    "l_columns = [f'{_}_lane_role' for _ in RADIANT_SIDE + DIRE_SIDE]\n",
    "t_columns = [f'{_}_rank_tier' for _ in RADIANT_SIDE + DIRE_SIDE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3094b32-0bb2-4dc8-90bb-2302658f922c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_arr = df[t_columns].values.astype('int64')\n",
    "h_arr = df[h_columns].values.astype('int64')\n",
    "p_arr = df[p_columns].values.astype('int64')\n",
    "\n",
    "\n",
    "# Players \n",
    "r_arr = df[r_columns].values.astype('int64')\n",
    "l_arr = df[l_columns].values.astype('int64') - 1\n",
    "\n",
    "num = len(players_regression_columns)//10\n",
    "players_regression_arr = df[players_regression_columns].values.astype('float32')\n",
    "players_regression_arr = np.concatenate(\n",
    "    [players_regression_arr[:, None, i*num:num*(i+1)] for i in range(10)], \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Teams \n",
    "num = len(teams_regression_columns)//2\n",
    "teams_regression_arr = df[teams_regression_columns].values.astype('float32')\n",
    "teams_regression_arr = np.concatenate(\n",
    "    [teams_regression_arr[:, None, i*num:num*(i+1)] for i in range(2)], \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "win_arr = df['radiant_win'].values\n",
    "win_arr = np.concatenate([win_arr[:, None], ~win_arr[:, None]], axis=-1).astype('float32')\n",
    "duration_arr = df['duration'].values.astype('float32')\n",
    "duration_arr = np.concatenate([duration_arr[:, None], duration_arr[:, None]], axis=-1).astype('float32')\n",
    "\n",
    "# Others\n",
    "matchIDArr = df['match_id'].values.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e6ae0a2-1082-4381-9fa5-3c0826d2baac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flattenHeroesArr = h_arr.flatten()\n",
    "setHeroesArr = set(flattenHeroesArr)\n",
    "playedGamesH = {p:0 for p in setHeroesArr}\n",
    "for p in flattenHeroesArr:\n",
    "    playedGamesH[p] += 1\n",
    "\n",
    "heroesPlayedGames = pd.DataFrame(\n",
    "    data = list(playedGamesH.values()),\n",
    "    index = list(id_to_hero.values())[:-1],\n",
    "    columns = ['played_games']\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(25, 25))\n",
    "sns.barplot(\n",
    "    x=heroesPlayedGames['played_games'], \n",
    "    y=heroesPlayedGames.index, \n",
    "    palette=\"Blues_d\",\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "fig.savefig('output/heroes_pickrate', bbox_inches='tight')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d3e1998-f7de-4b0c-9cd1-3bd352e03b2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indexex = np.arange(0, len(df))\n",
    "test_indexes = indexex[-test_size:]\n",
    "val_indexes   = indexex[-(test_size+val_size):-test_size]\n",
    "train_indexes = indexex[:-(test_size+val_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7981191-628d-47e2-9f48-a967b880db2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes_ohe = np.zeros([h_arr.shape[0], h_arr.shape[1], h_arr.max()+1])\n",
    "\n",
    "for r_idx, row in enumerate(h_arr):\n",
    "    for c_idx, h_idx in enumerate(row):\n",
    "        heroes_ohe[r_idx, c_idx, h_idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e45dbe0a-480b-4e3b-a4fa-2610048d1848",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = players_regression_arr[train_indexes]\n",
    "Ytrain = heroes_ohe[train_indexes]\n",
    "\n",
    "Xval = players_regression_arr[val_indexes]\n",
    "Yval = heroes_ohe[val_indexes]\n",
    "\n",
    "Xtest = players_regression_arr[test_indexes]\n",
    "Ytest = heroes_ohe[test_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "435ecdf3-b5f0-411d-a7ea-b792f4154534",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # --------------------------------------- #\n",
    "# Ytrain = [\n",
    "#     players_regression_arr[train_indexes],\n",
    "#     l_arr[train_indexes],\n",
    "#     r_arr[train_indexes],\n",
    "    \n",
    "#     teams_regression_arr[train_indexes],\n",
    "#     win_arr[train_indexes],\n",
    "#     duration_arr[train_indexes],\n",
    "#     np.concatenate([win_arr[:, None], win_arr[:, None]*-1+1], axis=1)[train_indexes],\n",
    "# ]\n",
    "\n",
    "# Xtrain = [\n",
    "#     h_arr[train_indexes],\n",
    "#     p_arr[train_indexes],\n",
    "#     t_arr[train_indexes],\n",
    "# ]\n",
    "# # --------------------------------------- #\n",
    "# Yval = [\n",
    "#     players_regression_arr[val_indexes],\n",
    "#     l_arr[val_indexes],\n",
    "#     r_arr[val_indexes],\n",
    "    \n",
    "#     teams_regression_arr[val_indexes],\n",
    "#     win_arr[val_indexes],\n",
    "#     duration_arr[val_indexes],\n",
    "#     np.concatenate([win_arr[:, None], win_arr[:, None]*-1+1], axis=1)[val_indexes],\n",
    "# ]\n",
    "\n",
    "# Xval = [\n",
    "#     h_arr[val_indexes],\n",
    "#     p_arr[val_indexes],\n",
    "#     t_arr[val_indexes],\n",
    "# ]\n",
    "# # --------------------------------------- #\n",
    "# Ytest = [\n",
    "#     players_regression_arr[test_indexes],\n",
    "#     l_arr[test_indexes],\n",
    "#     r_arr[test_indexes],\n",
    "    \n",
    "#     teams_regression_arr[test_indexes],\n",
    "#     win_arr[test_indexes],\n",
    "#     duration_arr[test_indexes],\n",
    "#     np.concatenate([win_arr[:, None], win_arr[:, None]*-1+1], axis=1)[test_indexes],\n",
    "# ]\n",
    "\n",
    "# Xtest = [\n",
    "#     h_arr[test_indexes],\n",
    "#     p_arr[test_indexes],\n",
    "#     t_arr[test_indexes],\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced81f17-6465-406b-b7aa-2205bf33f703",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MODEL PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdfc584b-5077-4bb1-b1c5-bfeaed887778",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import Input\n",
    "from sklearn import metrics\n",
    "\n",
    "from transformers import AdamWeightDecay "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999c9c75-1134-4a66-8d2e-820b84a15f6b",
   "metadata": {},
   "source": [
    "#### inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c35dd0a3-e0b0-4759-94c5-e331a986b292",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inf(y_true, y_pred, window = 0.05):\n",
    "    import seaborn as sns\n",
    "    from sklearn import metrics\n",
    "    from matplotlib import pyplot as plt\n",
    "    \n",
    "    \n",
    "    assert len(y_true) == len(y_pred), 'y_true != y_pred'\n",
    "\n",
    "    try:\n",
    "        y_true = y_true[:, 0]\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        y_pred = y_pred[:, 0]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    def accuracy(y_true, y_pred):\n",
    "        return 1 - np.abs(np.round(y_pred) - y_true).sum()/len(y_true)\n",
    "\n",
    "\n",
    "    def delta_probability_mean_score(y_true, y_pred, d1, d2):\n",
    "        \"\"\" Calculate probability_mean_score in window from d1 to d2\n",
    "        for example:\n",
    "            d1 = 0.\n",
    "            d2 = 0.5\n",
    "        this will calculate probability_mean_score from this window (probability_mean_score for 0 label)\n",
    "        \"\"\"\n",
    "        if d2 < d1:\n",
    "            d2, d1 = d1, d2\n",
    "        arr = y_true[(y_pred >= d1) & (y_pred <= d2)] - y_pred[(y_pred >= d1) & (y_pred <= d2)]\n",
    "        return (arr.sum()/len(arr))*100\n",
    "\n",
    "\n",
    "    def delta_accuracy(y_true, y_pred, d1, d2):    \n",
    "        if d2 < d1:\n",
    "            d2, d1 = d1, d2\n",
    "        y_true, y_pred = y_true[(y_pred >= d1) & (y_pred <= d2)], y_pred[(y_pred >= d1) & (y_pred <= d2)]\n",
    "\n",
    "        if len(y_pred) == 0:\n",
    "            return None, None\n",
    "        else:\n",
    "            return accuracy(y_true, y_pred), len(y_pred)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_true,  y_pred)\n",
    "    auc = metrics.roc_auc_score(y_true, y_pred)\n",
    "    print('Balance Y :', round(np.array(y_true).sum()/len(y_true), 3))\n",
    "    print('Accuracy  :', round(accuracy(y_true, y_pred), 3))\n",
    "    print('Precision :', round(metrics.precision_score(y_true, np.around(y_pred)), 3))\n",
    "    print('Recall    :', round(metrics.recall_score(y_true, np.around(y_pred)), 3))\n",
    "    print('AUC       :', round(auc, 3))\n",
    "    print()\n",
    "    print('Confusion matrix')\n",
    "    print(metrics.confusion_matrix(y_true, np.around(y_pred)))\n",
    "    print()\n",
    "    \n",
    "\n",
    "    sns.histplot(y_pred, bins = 100, ax = axes[0])\n",
    "    axes[1].plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "    axes[1].legend(loc=4)\n",
    "    \n",
    "    best_model = pd.DataFrame()\n",
    "    delta = np.arange(0., 1.0, window)\n",
    "    # we will collect abs score in this list, then we calculate average score \n",
    "    abs_score_list = []\n",
    "    \n",
    "    pred_len = len(y_pred)\n",
    "    for d in delta:\n",
    "        acc, samples = delta_accuracy(y_true, y_pred, d, d + window)\n",
    "        if samples != None:\n",
    "            score = round(delta_probability_mean_score(y_true, y_pred, d, d + window), 1)\n",
    "\n",
    "            if d < 0.5:\n",
    "                column = f\"{int(100 - round(d, 2)*100)}% - {int(100 - round(d+window, 2)*100)} %\"\n",
    "            else:\n",
    "                column = f\"{int(round(d, 2)*100)}% - {int(round(d+window, 2)*100)} %\"\n",
    "\n",
    "            best_model.loc['Accuracy', column] = str(round(acc*100, 2)) + ' %'\n",
    "            best_model.loc['Mean porabalistic error', column] = str(round(score, 3))\n",
    "            best_model.loc['Samples%', column] = str(int(samples*100/pred_len)) \n",
    "            best_model.loc['Samples', column] = str(samples)\n",
    "\n",
    "\n",
    "            abs_score_list.append(abs(score))\n",
    "\n",
    "    print(f\"Abs probability_mean_score per windows: {round(np.array(abs_score_list).mean(), 3)}\")\n",
    "    print('Number of predictions :', pred_len)\n",
    "    print()\n",
    "    \n",
    "    display(best_model)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092ebb9f-7f7d-44ba-b4e5-73855f7f84cf",
   "metadata": {},
   "source": [
    "#### CustomMetricCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "417a3cee-d51b-4c4a-bddb-aa9c207fa852",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomCheckpoint(keras.callbacks.Callback):\n",
    "    def __init__(self, board_name, monitor, mode, path):\n",
    "        super(CustomCheckpoint, self).__init__()\n",
    "        self.board_name = board_name\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "        self.path = path\n",
    "        \n",
    "        self.best = -np.inf if mode == 'max' else np.inf\n",
    "\n",
    "    def _save(self):\n",
    "        self.model.save(self.path + self.board_name + f'_{self.monitor}.h5', include_optimizer=False)\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        l = logs.get(self.monitor)\n",
    "        if self.mode == 'max':\n",
    "            if l > self.best:\n",
    "                self.best = l\n",
    "                self._save()\n",
    "                \n",
    "        if self.mode == 'min':\n",
    "            if l < self.best:\n",
    "                self.best = l\n",
    "                self._save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8634916b-8612-4918-86f7-57402635a9ea",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x285988afdc0>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def scheduler(step):\n",
    "    step+=1\n",
    "    arg1 = np.reciprocal(np.sqrt(step))\n",
    "    arg2 = step * (14 ** -1.1)\n",
    "    value = (np.reciprocal(np.sqrt(18)) * np.minimum(arg1, arg2)) * 5e-3\n",
    "    return value\n",
    "\n",
    "lr_schedule = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "epochs = [scheduler(x) for x in range(50)]\n",
    "plt.plot(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36343f3c-5543-41fd-9d73-989495521a2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TransformerBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91c7191c-579e-408d-b39e-79edf8f2740c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.15, name = None, **kwargs):\n",
    "        super(TransformerBlock, self).__init__(name=name)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.rate = rate\n",
    "        \n",
    "        self.att = keras.layers.MultiHeadAttention(num_heads=self.num_heads, key_dim=self.embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [\n",
    "                keras.layers.Dense(self.ff_dim, activation = 'gelu'),\n",
    "                keras.layers.Dropout(self.rate),\n",
    "                keras.layers.Dense(self.embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        attn_output = self.att(\n",
    "            query=inputs, \n",
    "            value=inputs, \n",
    "            key=inputs,\n",
    "        )\n",
    "        norm1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(norm1, training=training)\n",
    "        norm2 = self.layernorm2(norm1 + ffn_output)\n",
    "        return norm2\n",
    "    \n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'embed_dim': self.embed_dim,\n",
    "                  'num_heads': self.num_heads,\n",
    "                  'ff_dim'   : self.ff_dim,\n",
    "                  'rate'     : self.rate}\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880f01ec-8c0a-459f-ba00-a4f6f4afb62b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### AttentionBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bacd43bc-4711-4093-b767-51b127efbdf6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttentionBlock(keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.15, name = None, **kwargs):\n",
    "        super(AttentionBlock, self).__init__(name=name)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.rate = rate\n",
    "        \n",
    "        self.layernorm = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.att = keras.layers.MultiHeadAttention(num_heads=self.num_heads, key_dim=self.embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [\n",
    "                keras.layers.Dense(self.ff_dim, activation = 'gelu'),\n",
    "                keras.layers.Dropout(self.rate),\n",
    "                keras.layers.Dense(self.embed_dim),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        \n",
    "    def call(self, radiant, dire, training=None):\n",
    "        radiant_ = self.att(\n",
    "            query=radiant,\n",
    "            value=dire,\n",
    "            key=dire,\n",
    "        )\n",
    "        dire_ = self.att(\n",
    "            query=dire,\n",
    "            value=radiant,\n",
    "            key=radiant,\n",
    "        )\n",
    "        \n",
    "        radiant = self.ffn(radiant_) + radiant\n",
    "        dire = self.ffn(dire_) + dire\n",
    "        \n",
    "        radiant = self.layernorm(radiant)\n",
    "        dire = self.layernorm(dire)\n",
    "        \n",
    "        return radiant, dire\n",
    "    \n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'embed_dim': self.embed_dim,\n",
    "                  'num_heads': self.num_heads,\n",
    "                  'ff_dim'   : self.ff_dim,\n",
    "                  'rate'     : self.rate}\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afe2682-5c6b-4e4c-8a7f-dcfb0d44afb6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### EmbBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bbed2a7-f2c5-4086-b05e-6fc385dbe0ee",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EmbBlock(keras.layers.Layer):\n",
    "    def __init__(self, in_dim, out_dim, name=None, **kwargs):\n",
    "        super(EmbBlock, self).__init__(name=name)\n",
    "        self.in_dim  = in_dim\n",
    "        self.out_dim = out_dim       \n",
    "        \n",
    "        self.positions = tf.cast([[0, 0, 0, 0, 0, 1, 1, 1, 1, 1]], dtype='int32')\n",
    "        \n",
    "        self.ranks_emb = keras.layers.Embedding(10, self.in_dim)\n",
    "        self.pos_emb   = keras.layers.Embedding(2, self.in_dim)\n",
    "        \n",
    "        self.ffn_layer = keras.layers.Dense(self.in_dim)\n",
    "        self.dropout   = keras.layers.Dropout(0.2)\n",
    "        self.layer     = keras.layers.Dense(self.out_dim, activation = 'gelu')\n",
    "        \n",
    "    def call(self, players, heroes, ranks, training=None):\n",
    "        pos = self.pos_emb(self.positions)\n",
    "        pos = tf.repeat(pos, tf.shape(players)[0], axis = 0)\n",
    "        \n",
    "        ranks_r = ranks[:, :5]//10\n",
    "        ranks_d = ranks[:, 5:]//10    \n",
    "        ranks_r = self.ranks_emb(ranks_r)\n",
    "        ranks_d = self.ranks_emb(ranks_d)\n",
    "        ranks = tf.concat([ranks_r, ranks_d], axis=1)\n",
    "        \n",
    "    \n",
    "        x = self.ffn_layer(\n",
    "            tf.concat([players, heroes], axis=-1)\n",
    "        )\n",
    "        x = x + ranks + pos\n",
    "        x = self.layer(x)\n",
    "        \n",
    "        radiant, dire = x[:, :5], x[:, 5:]\n",
    "        return radiant, dire\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'in_dim': self.in_dim,\n",
    "                  'out_dim': self.out_dim}\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d3511d-d520-47c6-8b7c-e8e8a55a277d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70b93c99-c215-4f5b-884d-f31380f73110",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Masking(keras.layers.Layer):\n",
    "    def __init__(self, rate=0.01, name=None, **kwargs):\n",
    "        super(Masking, self).__init__(name=name)\n",
    "        self.rate  = rate\n",
    "        \n",
    "    def call(self, x, training=None):\n",
    "        if training and self.trainable:\n",
    "            # > rate cause tf.where works stupid\n",
    "            inp_mask = tf.random.uniform(tf.shape(x)) > self.rate\n",
    "            x = tf.where(inp_mask, x, 0)\n",
    "        return x\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {'rate': self.rate}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cfabc7-e408-43d2-9eda-5b9ff4c1ca56",
   "metadata": {},
   "source": [
    "### PosEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5150f71f-90b6-41a5-bd19-7ea98fd6c961",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PosEncoding(keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, name=None, **kwargs):\n",
    "        super(PosEncoding, self).__init__(name=name)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.positions = tf.cast([[0, 0, 0, 0, 0, 1, 1, 1, 1, 1]], dtype='int32')\n",
    "        self.pos_emb   = keras.layers.Embedding(2, self.embed_dim)\n",
    "        \n",
    "    def call(self, x, training=None):\n",
    "        pos = self.pos_emb(self.positions)\n",
    "        pos = tf.repeat(pos, tf.shape(x)[0], axis = 0)\n",
    "        return x + pos\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'embed_dim': self.embed_dim}\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85849e9-ce9c-46a8-b725-7c60955059f5",
   "metadata": {},
   "source": [
    "### ArcLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e20216cc-c71a-4c1a-ab86-fdd21a3ff8c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ArcLayer(keras.layers.Layer):\n",
    "    def __init__(self, units, kernel_regularizer=None, **kwargs):\n",
    "        super(ArcLayer, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.kernel_regularizer = kernel_regularizer\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=[input_shape[-1], self.units],\n",
    "            dtype=tf.float32,\n",
    "            initializer=keras.initializers.HeNormal(),\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            trainable=True,\n",
    "            name='kernel',\n",
    "        )\n",
    "        self.built = True\n",
    "        \n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        weights = tf.nn.l2_normalize(self.kernel, axis=0)\n",
    "        return tf.matmul(inputs, weights)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"units\": self.units,\n",
    "            \"kernel_regularizer\": self.kernel_regularizer,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644e6063-cfb6-41a1-a5e8-30c1906dbc2b",
   "metadata": {},
   "source": [
    "### ArcLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "77be0794-3333-4d8f-af86-c8348fc2b523",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ArcLoss(tf.keras.losses.Loss):\n",
    "    \"\"\"Additive angular margin loss.\n",
    "    \n",
    "    ArcFace: Additive Angular Margin Loss for Deep Face Recognition:\n",
    "        https://arxiv.org/pdf/1801.07698.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin=0.5, scale=64, name=\"arcloss\"):\n",
    "        \"\"\"Build an additive angular margin loss object for Keras model.\"\"\"\n",
    "        super().__init__(name=name)\n",
    "        self.margin = margin\n",
    "        self.scale = scale\n",
    "        self.threshold = tf.math.cos(math.pi - margin)\n",
    "        self.cos_m = tf.math.cos(margin)\n",
    "        self.sin_m = tf.math.sin(margin)\n",
    "\n",
    "        # Safe margin: https://github.com/deepinsight/insightface/issues/108\n",
    "        self.safe_margin = self.sin_m * margin\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, y_true, y_pred):\n",
    "        shape = tf.shape(y_true)\n",
    "        b, t, n = shape[0], shape[1], shape[2]\n",
    "        y_true = tf.reshape(y_true, [b*t, n])\n",
    "        y_pred = tf.reshape(y_pred, [b*t, n])\n",
    "        # |x|: (B, 10, N) -> (B*10, N)\n",
    "        # B - batch size\n",
    "        # 10 - num of players in match\n",
    "        # N - num of heroes in dota\n",
    "        \n",
    "        # ------------------------------------------- #\n",
    "        # Calculate the cosine value of theta + margin.\n",
    "        cos_t = y_pred\n",
    "        sin_t = tf.math.sqrt(1 - tf.math.square(cos_t))\n",
    "\n",
    "        cos_t_margin = tf.where(cos_t > self.threshold,\n",
    "                                cos_t * self.cos_m - sin_t * self.sin_m,\n",
    "                                cos_t - self.safe_margin)\n",
    "\n",
    "        # The labels here had already been onehot encoded.\n",
    "        mask = y_true\n",
    "        cos_t_onehot = cos_t * mask\n",
    "        cos_t_margin_onehot = cos_t_margin * mask\n",
    "\n",
    "        # Calculate the final scaled logits.\n",
    "        logits = (cos_t + cos_t_margin_onehot - cos_t_onehot) * self.scale\n",
    "\n",
    "        losses = tf.nn.softmax_cross_entropy_with_logits(y_true, logits)\n",
    "\n",
    "        return losses\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(ArcLoss, self).get_config()\n",
    "        config.update({\"margin\": self.margin, \"scale\": self.scale})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed88c514-2f78-463e-b27a-5f68ec04a108",
   "metadata": {},
   "source": [
    "### L2Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "88bc7d55-bdb0-4f8e-99db-0ac254de8957",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2Normalization(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        inputs = tf.nn.l2_normalize(inputs, axis=0)\n",
    "        return inputs\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b4d034ce-ed76-45e8-a175-55b035a64179",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_objects = {\n",
    "    'Masking': Masking,\n",
    "    'EmbBlock': EmbBlock,\n",
    "    'TransformerBlock': TransformerBlock,\n",
    "    'AttentionBlock': AttentionBlock,\n",
    "    'PosEncoding': PosEncoding,\n",
    "    'ArcLayer': ArcLayer,\n",
    "    'ArcLoss': ArcLoss,\n",
    "    'L2Normalization': L2Normalization\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6643545e-3c8d-460b-a15a-9457c2ead8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25.592967784139454, 11.74734012447073)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(p_arr.max()+1)**0.5, (h_arr.max()+1)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fa87ae-3826-4f05-9b93-a14f990e44fe",
   "metadata": {},
   "source": [
    "# Perfomance -> heroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "b3b1f9f5-715c-4559-ace7-52aebb2d2646",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " per_hero_regression_input (Inp  [(None, 10, 14)]    0           []                               \n",
      " utLayer)                                                                                         \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 10, 64)       5248        ['per_hero_regression_input[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " PosEncding (PosEncoding)       (None, 10, 64)       128         ['sequential[0][0]']             \n",
      "                                                                                                  \n",
      " self_attention_block0 (Transfo  (None, 10, 64)      149504      ['PosEncding[0][0]']             \n",
      " rmerBlock)                                                                                       \n",
      "                                                                                                  \n",
      " self_attention_block1 (Transfo  (None, 10, 64)      149504      ['self_attention_block0[0][0]']  \n",
      " rmerBlock)                                                                                       \n",
      "                                                                                                  \n",
      " self_attention_block2 (Transfo  (None, 10, 64)      149504      ['self_attention_block1[0][0]']  \n",
      " rmerBlock)                                                                                       \n",
      "                                                                                                  \n",
      " self_attention_block3 (Transfo  (None, 10, 64)      149504      ['self_attention_block2[0][0]']  \n",
      " rmerBlock)                                                                                       \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 10, 64)      0           ['self_attention_block3[0][0]',  \n",
      " da)                                                              'self_attention_block0[0][0]']  \n",
      "                                                                                                  \n",
      " self_attention_block4 (Transfo  (None, 10, 64)      149504      ['tf.__operators__.add[0][0]']   \n",
      " rmerBlock)                                                                                       \n",
      "                                                                                                  \n",
      " self_attention_block5 (Transfo  (None, 10, 64)      149504      ['self_attention_block4[0][0]']  \n",
      " rmerBlock)                                                                                       \n",
      "                                                                                                  \n",
      " self_attention_block6 (Transfo  (None, 10, 64)      149504      ['self_attention_block5[0][0]']  \n",
      " rmerBlock)                                                                                       \n",
      "                                                                                                  \n",
      " self_attention_block7 (Transfo  (None, 10, 64)      149504      ['self_attention_block6[0][0]']  \n",
      " rmerBlock)                                                                                       \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 10, 64)      0           ['self_attention_block7[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " classification_out (Sequential  (None, 10, 138)     3296        ['tf.__operators__.add_1[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,204,704\n",
      "Trainable params: 1,204,544\n",
      "Non-trainable params: 160\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "d_model = 64\n",
    "ff_dim = 128\n",
    "num_heads = 8\n",
    "layer_num = 8\n",
    "dropout = 0.15\n",
    "final_heroes_emb_size = 16\n",
    "skip_connection = 4\n",
    "\n",
    "# ---------------------------------------------- #\n",
    "per_hero_regression_input = Input((10, len(FEATURES)), name='per_hero_regression_input')\n",
    "\n",
    "inputs = [per_hero_regression_input]\n",
    "\n",
    "\n",
    "pos = PosEncoding(embed_dim=d_model, name='PosEncding')\n",
    "in_ffn = keras.Sequential([\n",
    "    keras.layers.Dense(d_model, use_bias=False, activation='gelu'),\n",
    "    keras.layers.Dropout(dropout),\n",
    "\n",
    "    keras.layers.Dense(d_model, use_bias=False),\n",
    "    keras.layers.BatchNormalization(axis=-1),\n",
    "    keras.layers.Activation('gelu'),\n",
    "    keras.layers.Dropout(dropout),\n",
    "])\n",
    "out_ffn = keras.Sequential([\n",
    "    keras.layers.Dense(final_heroes_emb_size, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    L2Normalization(),\n",
    "    ArcLayer(h_arr.max()+1),\n",
    "], name='classification_out')\n",
    "# ---------------------------------------------- #\n",
    "x = in_ffn(per_hero_regression_input)\n",
    "x = pos(x)\n",
    "\n",
    "skip_conection = None\n",
    "for i in range(layer_num):\n",
    "    self_attention = TransformerBlock(embed_dim=d_model, num_heads=num_heads, ff_dim=ff_dim, name=f'self_attention_block{i}')\n",
    "    # x = self_attention(x)\n",
    "    if (i+1)%skip_connection == 0:\n",
    "        x = self_attention(x)\n",
    "        x = skip_conection = x + skip_conection\n",
    "    elif i == 0:\n",
    "        x = skip_conection = self_attention(x)\n",
    "    else:\n",
    "        x = self_attention(x)\n",
    "        \n",
    "outputs = [out_ffn(x)]\n",
    "\n",
    "# --------------------------------------- #\n",
    "model = keras.Model(\n",
    "    inputs=inputs,\n",
    "    outputs=outputs, \n",
    ")\n",
    "\n",
    "# --------------------------------------- #\n",
    "# Test save-n-load, predict; Summary\n",
    "# pred = model.predict(Xtrain[-256:])\n",
    "# model.save(f\"output/test.h5\")\n",
    "# model = keras.models.load_model(f'output/test.h5', compile=False, custom_objects=custom_objects)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "5dff6cb7-3741-495f-87fc-fbd3b17763f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100000000\n",
      "56/56 [==============================] - 18s 217ms/step - loss: 36.7897 - val_loss: 37.7263 - lr: 6.4654e-05\n",
      "Epoch 2/100000000\n",
      "56/56 [==============================] - 11s 203ms/step - loss: 36.2168 - val_loss: 36.3509 - lr: 1.2931e-04\n",
      "Epoch 3/100000000\n",
      "56/56 [==============================] - 11s 205ms/step - loss: 36.1276 - val_loss: 36.1743 - lr: 1.9396e-04\n",
      "Epoch 4/100000000\n",
      "56/56 [==============================] - 11s 204ms/step - loss: 36.0144 - val_loss: 36.4987 - lr: 2.5861e-04\n",
      "Epoch 5/100000000\n",
      "56/56 [==============================] - 11s 204ms/step - loss: 36.0037 - val_loss: 36.2616 - lr: 3.2327e-04\n",
      "Epoch 6/100000000\n",
      "56/56 [==============================] - 11s 201ms/step - loss: 36.0168 - val_loss: 36.2899 - lr: 3.8792e-04\n",
      "Epoch 7/100000000\n",
      "56/56 [==============================] - 11s 200ms/step - loss: 36.0434 - val_loss: 36.3704 - lr: 4.4544e-04\n",
      "Epoch 8/100000000\n",
      "56/56 [==============================] - 11s 199ms/step - loss: 36.0326 - val_loss: 36.2323 - lr: 4.1667e-04\n",
      "Epoch 9/100000000\n",
      "56/56 [==============================] - 11s 200ms/step - loss: 36.0585 - val_loss: 36.2950 - lr: 3.9284e-04\n",
      "Epoch 10/100000000\n",
      "56/56 [==============================] - 11s 200ms/step - loss: 36.0369 - val_loss: 36.2030 - lr: 3.7268e-04\n",
      "Epoch 11/100000000\n",
      "56/56 [==============================] - 11s 200ms/step - loss: 36.0390 - val_loss: 36.3857 - lr: 3.5533e-04\n",
      "Epoch 12/100000000\n",
      "56/56 [==============================] - 11s 202ms/step - loss: 36.0324 - val_loss: 36.2766 - lr: 3.4021e-04\n",
      "Epoch 13/100000000\n",
      "56/56 [==============================] - 11s 200ms/step - loss: 36.0301 - val_loss: 36.2821 - lr: 3.2686e-04\n",
      "Epoch 14/100000000\n",
      "56/56 [==============================] - 11s 202ms/step - loss: 36.1199 - val_loss: 36.2607 - lr: 3.1497e-04\n",
      "Epoch 15/100000000\n",
      "56/56 [==============================] - 12s 206ms/step - loss: 36.0155 - val_loss: 36.1739 - lr: 3.0429e-04\n",
      "Epoch 16/100000000\n",
      "56/56 [==============================] - 11s 202ms/step - loss: 36.0524 - val_loss: 36.2362 - lr: 2.9463e-04\n",
      "Epoch 17/100000000\n",
      "56/56 [==============================] - 11s 204ms/step - loss: 36.0429 - val_loss: 36.4713 - lr: 2.8583e-04\n",
      "Epoch 18/100000000\n",
      "56/56 [==============================] - 11s 205ms/step - loss: 36.0314 - val_loss: 36.0395 - lr: 2.7778e-04\n",
      "Epoch 19/100000000\n",
      "56/56 [==============================] - 11s 205ms/step - loss: 36.0410 - val_loss: 36.3314 - lr: 2.7037e-04\n",
      "Epoch 20/100000000\n",
      "56/56 [==============================] - 11s 205ms/step - loss: 36.0171 - val_loss: 36.3449 - lr: 2.6352e-04\n",
      "Epoch 21/100000000\n",
      "56/56 [==============================] - 11s 201ms/step - loss: 36.0405 - val_loss: 36.2712 - lr: 2.5717e-04\n",
      "Epoch 22/100000000\n",
      "56/56 [==============================] - 11s 201ms/step - loss: 36.0890 - val_loss: 36.4015 - lr: 2.5126e-04\n",
      "Epoch 23/100000000\n",
      "56/56 [==============================] - 11s 202ms/step - loss: 36.0597 - val_loss: 36.2617 - lr: 2.4574e-04\n",
      "Epoch 24/100000000\n",
      "56/56 [==============================] - 11s 202ms/step - loss: 36.0364 - val_loss: 36.1734 - lr: 2.4056e-04\n",
      "Epoch 25/100000000\n",
      "56/56 [==============================] - 11s 204ms/step - loss: 36.0227 - val_loss: 36.2297 - lr: 2.3570e-04\n",
      "Epoch 26/100000000\n",
      "56/56 [==============================] - 11s 204ms/step - loss: 36.0565 - val_loss: 36.3559 - lr: 2.3113e-04\n",
      "Epoch 27/100000000\n",
      "56/56 [==============================] - 11s 203ms/step - loss: 36.0884 - val_loss: 36.3177 - lr: 2.2680e-04\n",
      "Epoch 28/100000000\n",
      "56/56 [==============================] - 11s 204ms/step - loss: 36.0937 - val_loss: 36.4672 - lr: 2.2272e-04\n",
      "Epoch 29/100000000\n",
      "56/56 [==============================] - 11s 205ms/step - loss: 36.0519 - val_loss: 36.2662 - lr: 2.1884e-04\n",
      "Epoch 30/100000000\n",
      "56/56 [==============================] - 11s 202ms/step - loss: 36.1003 - val_loss: 36.2486 - lr: 2.1517e-04\n",
      "Epoch 31/100000000\n",
      "56/56 [==============================] - 11s 201ms/step - loss: 36.0131 - val_loss: 36.3039 - lr: 2.1167e-04\n",
      "Epoch 32/100000000\n",
      "56/56 [==============================] - 11s 202ms/step - loss: 36.1311 - val_loss: 36.4720 - lr: 2.0833e-04\n",
      "Epoch 33/100000000\n",
      "56/56 [==============================] - 11s 201ms/step - loss: 36.0226 - val_loss: 36.3709 - lr: 2.0515e-04\n",
      "Epoch 34/100000000\n",
      "56/56 [==============================] - 11s 205ms/step - loss: 36.0369 - val_loss: 36.1087 - lr: 2.0211e-04\n",
      "Epoch 35/100000000\n",
      "56/56 [==============================] - 11s 203ms/step - loss: 36.0384 - val_loss: 36.3022 - lr: 1.9920e-04\n",
      "Epoch 36/100000000\n",
      "56/56 [==============================] - 11s 203ms/step - loss: 36.0982 - val_loss: 36.4426 - lr: 1.9642e-04\n",
      "Epoch 37/100000000\n",
      "56/56 [==============================] - 11s 200ms/step - loss: 36.0768 - val_loss: 36.1817 - lr: 1.9375e-04\n",
      "Epoch 38/100000000\n",
      "56/56 [==============================] - 11s 202ms/step - loss: 36.0312 - val_loss: 36.0719 - lr: 1.9118e-04\n"
     ]
    }
   ],
   "source": [
    "optimizer = tfa.optimizers.AdamW(weight_decay=0.1, learning_rate=3e-4, epsilon=1e-6, clipvalue=1.)\n",
    "# optimizer = AdamWeightDecay(learning_rate=3e-4, weight_decay_rate=0.1, epsilon=1e-7, clipvalue=0.5, clipnorm=1.)\n",
    "# optimizer = keras.optimizers.Adam(1e-3, amsgrad=True, epsilon=1e-7, clipvalue=0.5)\n",
    "# optimizer = keras.optimizers.SGD(learning_rate=3e-4, decay=1e-6, momentum=0.9, nesterov=True, clipvalue=1.0)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=ArcLoss(), #keras.losses.CategoricalCrossentropy(),\n",
    "    # metrics=['accuracy', keras.metrics.AUC(num_thresholds=60, name='auc')]\n",
    ")\n",
    "\n",
    "board_name = datetime.datetime.now().strftime(\"%Y-%m-%d - %H-%M-%S\")\n",
    "log_dir = f\"logs/fit/public/params-{model.count_params()} --- data-{board_name}\"\n",
    "\n",
    "monitor = \"val_loss\"\n",
    "try:\n",
    "    with tf.device('/gpu:0'):\n",
    "        tb = keras.callbacks.TensorBoard(log_dir=log_dir),\n",
    "        es = keras.callbacks.EarlyStopping(monitor=monitor, mode='min', patience=20, restore_best_weights=True),\n",
    "        cc = CustomCheckpoint(board_name, monitor=monitor, mode='min', path='CustomCallbackCheckpoints/')\n",
    "        model.fit(\n",
    "            Xtrain, Ytrain,\n",
    "            validation_data=(Xval, Yval),\n",
    "            callbacks=[lr_schedule, es, tb, cc],\n",
    "            verbose=1,\n",
    "            epochs=10**8,\n",
    "            batch_size=1024,\n",
    "            shuffle=True,\n",
    "            # sample_weight=np.arange(0.5, 1, 0.5/len(train_indexes)),\n",
    "        )\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "4838cb01-e348-4ff1-a216-9d835afdda3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"2022-08-18 - 03-42-28_val_auc\"\n",
    "name = \"2022-08-18 - 02-39-43_val_auc\"\n",
    "model = keras.models.load_model(f\"CustomCallbackCheckpoints/{name}.h5\", custom_objects=custom_objects, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "fbc95594-5f35-4246-bfa8-75a6a1aea08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "6996a667-a703-43f2-a483-8b9450210e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tf.nn.softmax(pred, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "6e705b57-01fa-4686-b1b8-ba378f016bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics1(true, pred):\n",
    "    true, pred = true.flatten(), pred.flatten()\n",
    "\n",
    "    accuracy = metrics.top_k_accuracy_score(true, pred, k=5)\n",
    "    AUCauc = metrics.roc_auc_score(true, pred)\n",
    "    log_loss = metrics.log_loss(true, pred)\n",
    "    precision = metrics.precision_score(true, pred)\n",
    "    recall = metrics.recall_score(true, pred)\n",
    "    return accuracy, auc, log_loss, precision, recall\n",
    "\n",
    "def eval_metrics2(true, pred):\n",
    "    true = true.reshape([true.shape[0] * true.shape[1], true.shape[2]])\n",
    "    pred = pred.reshape([pred.shape[0] * pred.shape[1], pred.shape[2]])\n",
    "    \n",
    "    accuracy = keras.metrics.categorical_accuracy(true, pred).numpy().mean()\n",
    "    auc = keras.metrics.AUC()(true, pred).numpy()\n",
    "    log_loss = keras.metrics.categorical_crossentropy(true, pred).numpy().mean()\n",
    "    k5 = keras.metrics.top_k_categorical_accuracy(true, pred, k=5).numpy().mean()\n",
    "    k10 = keras.metrics.top_k_categorical_accuracy(true, pred, k=10).numpy().mean()\n",
    "    return accuracy, auc, log_loss, k5, k10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "9d8c9bd1-35c8-4f6f-823a-eee31a346e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-18 - 02-39-43_val_auc\n",
      "(0.37946278, 0.96126384, 2.261273, 0.7177876, 0.85862947)\n"
     ]
    }
   ],
   "source": [
    "print(name)\n",
    "print(eval_metrics2(Ytest, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "394714bf-dae3-47f1-b6d1-16c4034450b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-18 - 02-39-43_val_auc\n",
      "(0.18775381, 0.5626434, 4.7079434, 0.48081642, 0.6582487)\n"
     ]
    }
   ],
   "source": [
    "\"Additive angular margin loss\"\n",
    "print(name)\n",
    "print(eval_metrics2(Ytest, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "894bcd73-ea33-443f-b1f7-172bcb802ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.array(list(set(h_arr.flatten())))\n",
    "\n",
    "layer = model.get_layer(\"classification_out\")\n",
    "if type(layer) == keras.Sequential:\n",
    "    layer = layer.layers[-1]\n",
    "    \n",
    "w = layer.weights[0].numpy().T\n",
    "W = w / np.linalg.norm(w, axis=-1, keepdims=True)\n",
    "W = W[ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "0d6840ad-349e-4755-8a86-708c449e6feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\royta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tsne = TSNE(\n",
    "    n_components=2, \n",
    "    perplexity=64, \n",
    "    early_exaggeration=12,\n",
    "    learning_rate='auto',\n",
    "    random_state=69,\n",
    "    init='random',\n",
    ")\n",
    "\n",
    "embed = tsne.fit_transform(W)\n",
    "x_, y_ = embed[:, 0], embed[:, 1]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(25, 25))\n",
    "sns.scatterplot(x_, y_, ax=ax)\n",
    "\n",
    "ax.axhline(0, c='black', alpha=0.25)\n",
    "ax.axvline(0, c='black', alpha=0.25)\n",
    "\n",
    "for x, y, i in zip(x_, y_, ids):\n",
    "    ax.text(x-.002, y+.0025, id_to_hero[i])\n",
    "    \n",
    "fig.savefig('output/embeddings/TSNE_heroes_softmax', bbox_inches='tight')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b7a993-cd50-4644-872c-0eb238fb11f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Heroes -> perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8d207eb9-b493-42ee-a6bf-05e3438b5bf3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " hero_input (InputLayer)        [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " player_input (InputLayer)      [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " masking_1 (Masking)            (None, 10)           0           ['hero_input[0][0]']             \n",
      "                                                                                                  \n",
      " players_embedding (Embedding)  (None, 10, 24)       15696       ['player_input[0][0]']           \n",
      "                                                                                                  \n",
      " heroes_embedding (Embedding)   (None, 10, 16)       2208        ['masking_1[0][0]']              \n",
      "                                                                                                  \n",
      " rank_input (InputLayer)        [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " emb_block (EmbBlock)           ((None, 5, 64),      7552        ['players_embedding[0][0]',      \n",
      "                                 (None, 5, 64))                   'heroes_embedding[0][0]',       \n",
      "                                                                  'rank_input[0][0]']             \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)         (None, 10, 64)       0           ['emb_block[0][0]',              \n",
      "                                                                  'emb_block[0][1]']              \n",
      "                                                                                                  \n",
      " transformer_block (Transformer  (None, 10, 64)      149504      ['tf.concat[0][0]']              \n",
      " Block)                                                                                           \n",
      "                                                                                                  \n",
      " transformer_block_1 (Transform  (None, 10, 64)      149504      ['transformer_block[0][0]']      \n",
      " erBlock)                                                                                         \n",
      "                                                                                                  \n",
      " transformer_block_2 (Transform  (None, 10, 64)      149504      ['transformer_block_1[0][0]']    \n",
      " erBlock)                                                                                         \n",
      "                                                                                                  \n",
      " transformer_block_3 (Transform  (None, 10, 64)      149504      ['transformer_block_2[0][0]']    \n",
      " erBlock)                                                                                         \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 10, 64)      0           ['transformer_block_3[0][0]',    \n",
      " da)                                                              'transformer_block[0][0]']      \n",
      "                                                                                                  \n",
      " transformer_block_4 (Transform  (None, 10, 64)      149504      ['tf.__operators__.add[0][0]']   \n",
      " erBlock)                                                                                         \n",
      "                                                                                                  \n",
      " transformer_block_5 (Transform  (None, 10, 64)      149504      ['transformer_block_4[0][0]']    \n",
      " erBlock)                                                                                         \n",
      "                                                                                                  \n",
      " transformer_block_6 (Transform  (None, 10, 64)      149504      ['transformer_block_5[0][0]']    \n",
      " erBlock)                                                                                         \n",
      "                                                                                                  \n",
      " transformer_block_7 (Transform  (None, 10, 64)      149504      ['transformer_block_6[0][0]']    \n",
      " erBlock)                                                                                         \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 5, 64)       0           ['transformer_block_7[0][0]']    \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None, 5, 64)       0           ['transformer_block_7[0][0]']    \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean (TFOpLambd  (None, 64)          0           ['tf.__operators__.getitem[0][0]'\n",
      " a)                                                              ]                                \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_1 (TFOpLam  (None, 64)          0           ['tf.__operators__.getitem_1[0][0\n",
      " bda)                                                            ]']                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2 (Sl  (None, 1, 64)       0           ['tf.math.reduce_mean[0][0]']    \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3 (Sl  (None, 1, 64)       0           ['tf.math.reduce_mean_1[0][0]']  \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.concat_1 (TFOpLambda)       (None, 2, 64)        0           ['tf.__operators__.getitem_2[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'tf.__operators__.getitem_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " sequential_2 (Sequential)      (None, 1)            16641       ['tf.math.reduce_mean[0][0]',    \n",
      "                                                                  'tf.math.reduce_mean_1[0][0]']  \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)      (None, 2, 64)        16576       ['tf.concat_1[0][0]']            \n",
      "                                                                                                  \n",
      " tf.concat_2 (TFOpLambda)       (None, 2)            0           ['sequential_2[0][0]',           \n",
      "                                                                  'sequential_2[1][0]']           \n",
      "                                                                                                  \n",
      " teams_regression_output (Dense  (None, 2, 14)       910         ['sequential_1[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " win_output (Softmax)           (None, 2)            0           ['tf.concat_2[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,255,615\n",
      "Trainable params: 1,255,615\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "d_model = 64\n",
    "ff_dim = 128\n",
    "num_heads = 8\n",
    "layer_num = 8\n",
    "dropout = 0.1\n",
    "\n",
    "hero_input   = Input(10, name='hero_input')\n",
    "player_input = Input(10, name='player_input')\n",
    "rank_input   = Input(10, name='rank_input')\n",
    "imputs = [hero_input, player_input, rank_input]\n",
    "\n",
    "# --------------------------------------- #\n",
    "masking = Masking(0.01)\n",
    "\n",
    "hEmbeddibg = keras.layers.Embedding(h_arr.max()+1, 16, name='heroes_embedding')\n",
    "pEmbeddibg = keras.layers.Embedding(p_arr.max()+1, 24, name='players_embedding')\n",
    "\n",
    "embBlock = EmbBlock(in_dim=d_model, out_dim=d_model, name='EmbBlock')\n",
    "\n",
    "# tBlock1  = TransformerBlock(embed_dim=d_model, num_heads=num_heads, ff_dim=ff_dim, rate=dropout, name='transformerBlock1')\n",
    "# aBlock1  = AttentionBlock(embed_dim=d_model, num_heads=num_heads, ff_dim=ff_dim, rate=dropout, name='attentionBlock1')\n",
    "\n",
    "# tBlock2  = TransformerBlock(embed_dim=d_model, num_heads=num_heads, ff_dim=ff_dim, rate=dropout, name='transformerBlock2')\n",
    "# aBlock2  = AttentionBlock(embed_dim=d_model, num_heads=num_heads, ff_dim=ff_dim, rate=dropout, name='attentionBlock2')\n",
    "\n",
    "# tBlock3  = TransformerBlock(embed_dim=d_model, num_heads=num_heads, ff_dim=ff_dim, rate=dropout, name='transformerBlock3')\n",
    "# aBlock3  = AttentionBlock(embed_dim=d_model, num_heads=num_heads, ff_dim=ff_dim, rate=dropout, name='attentionBlock3')\n",
    "\n",
    "# tBlock4  = TransformerBlock(embed_dim=d_model, num_heads=num_heads, ff_dim=ff_dim, rate=dropout, name='transformerBlock4')\n",
    "# aBlock4  = AttentionBlock(embed_dim=d_model, num_heads=num_heads, ff_dim=ff_dim, rate=dropout, name='attentionBlock4')\n",
    "\n",
    "# --------------------------------------- #\n",
    "players_ffn = keras.Sequential([\n",
    "    keras.layers.Dense(d_model, activation = 'gelu'),\n",
    "    keras.layers.Dropout(dropout),\n",
    "    keras.layers.Dense(d_model, activation = 'gelu'),\n",
    "    keras.layers.Dropout(dropout),\n",
    "])\n",
    "teams_ffn = keras.Sequential([\n",
    "    keras.layers.Dense(d_model*2, activation = 'gelu'),\n",
    "    keras.layers.Dropout(dropout),\n",
    "    keras.layers.Dense(d_model, activation = 'gelu'),\n",
    "])\n",
    "win_ffn = keras.Sequential([\n",
    "    keras.layers.Dense(d_model*2, activation = 'gelu'),\n",
    "    keras.layers.Dropout(dropout),\n",
    "    keras.layers.Dense(d_model, activation = 'gelu'),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "\n",
    "hero_input = masking(hero_input)\n",
    "p = pEmbeddibg(player_input)\n",
    "h = hEmbeddibg(hero_input)\n",
    "\n",
    "r, d = embBlock(p, h, rank_input)\n",
    "#  |r, d| -> (batch, 5, embed_dim), (batch, 5, embed_dim)\n",
    "\n",
    "# --------------------------------------- #\n",
    "# r_, d_ = tBlock1(r), tBlock1(d)\n",
    "# r, d = aBlock1(r_, d_)\n",
    "\n",
    "# r, d = tBlock2(r), tBlock2(d)\n",
    "# r, d = aBlock2(r, d)\n",
    "\n",
    "# r, d = tBlock3(r), tBlock3(d)\n",
    "# r, d = r + r_, d + d_\n",
    "# r, d = aBlock3(r, d)\n",
    "\n",
    "# r, d = tBlock4(r), tBlock4(d)\n",
    "\n",
    "# --------------------------------------- #\n",
    "# _r, _d = None, None\n",
    "# for i in range(layer_num):\n",
    "#     self_attention = TransformerBlock(embed_dim=d_model, num_heads=num_heads, ff_dim=ff_dim, name=f'self_attention_block{i}')\n",
    "#     cross_attenrion = AttentionBlock(embed_dim=d_model, num_heads=num_heads, ff_dim=ff_dim, name=f'cross_attention_block{i}')\n",
    "    \n",
    "#     if i%2 == 0:\n",
    "#         if _r is not None and _d is not None:\n",
    "#             r, d = r + _r, d + _d\n",
    "            \n",
    "#         _r, _d = self_attention(r), self_attention(d)\n",
    "#         _r, _d = cross_attenrion(_r, _d)\n",
    "#         r, d = _r, _d\n",
    "#     else:\n",
    "#         r, d = self_attention(r), self_attention(d)\n",
    "#         r, d = cross_attenrion(r, d)\n",
    "    \n",
    "# --------------------------------------- #\n",
    "# players = tf.concat([r, d], axis=1)\n",
    "# for i in range(layer_num):\n",
    "#     self_attention = TransformerBlock(embed_dim=d_model, num_heads=num_heads, ff_dim=ff_dim, name=f'self_attention_block{i}')\n",
    "#     players = self_attention(players)\n",
    "    \n",
    "# r, d = players[:, :5, :], players[:, 5:, :]\n",
    "\n",
    "# --------------------------------------- #\n",
    "players = tf.concat([r, d], axis=1)\n",
    "players_ = None\n",
    "for i in range(layer_num):\n",
    "    self_attention = TransformerBlock(embed_dim=d_model, num_heads=num_heads, ff_dim=ff_dim, name=f'self_attention_block{i}')\n",
    "    \n",
    "    if i%4 == 0:\n",
    "        if players_ is not None:\n",
    "            players = players + players_\n",
    "            \n",
    "        players_ = self_attention(players)\n",
    "        players = players_\n",
    "    else:\n",
    "        players = self_attention(players)\n",
    "        \n",
    "r, d = players[:, :5, :], players[:, 5:, :]\n",
    "\n",
    "# --------------------------------------- #\n",
    "# Concat and apply player_ffn for each player \n",
    "# [batch, 5, embed_dim], [batch, 5, embed_dim] -> [batch, 10, embed_dim]\n",
    "# players = players_ffn(tf.concat([r, d], axis=1))\n",
    "\n",
    "# [batch, 5, embed_dim], [batch, 5, embed_dim] -> [batch, embed_dim], [batch, embed_dim]\n",
    "team1, team2 = tf.reduce_mean(r, axis=1), tf.reduce_mean(d, axis=1) \n",
    "teams = tf.concat([\n",
    "    team1[:, tf.newaxis],\n",
    "    team2[:, tf.newaxis]\n",
    "    ], axis=1)\n",
    "\n",
    "teams = teams_ffn(teams)\n",
    "team1 = win_ffn(team1)\n",
    "team2 = win_ffn(team2)\n",
    "\n",
    "# --------------------------------------- #\n",
    "# For each player\n",
    "# players_regression_output = keras.layers.Dense(players_regression_arr.shape[-1], name='players_regression_output')\n",
    "# l_output = keras.layers.Dense(4, activation='softmax', name='l_output') # SparseCategoricalCrossentropy  \n",
    "# r_output = keras.layers.Dense(5, activation='softmax', name='r_output') # SparseCategoricalCrossentropy  \n",
    "\n",
    "# For each team\n",
    "teams_regression_output = keras.layers.Dense(teams_regression_arr.shape[-1], name='teams_regression_output') \n",
    "# duration_output = keras.layers.Dense(1, name='duration_output') \n",
    "# win_output = keras.layers.Dense(2, activation='softmax', name='win_output')  \n",
    "win_output = keras.layers.Softmax(name='win_output')\n",
    "\n",
    "\n",
    "outputs = [\n",
    "    # players_regression_output(players), \n",
    "    # l_output(players), \n",
    "    # r_output(players), \n",
    "    \n",
    "    teams_regression_output(teams),\n",
    "    # duration_output(teams),\n",
    "    win_output(tf.concat([team1, team2], axis=1)),\n",
    "]\n",
    "\n",
    "# --------------------------------------- #\n",
    "model = keras.Model(\n",
    "    inputs=imputs,\n",
    "    outputs=outputs, \n",
    ")\n",
    "\n",
    "pred = model.predict([x[-400:] for x in Xtrain])\n",
    "\n",
    "model.save(f\"test.h5\")\n",
    "model = keras.models.load_model(f'test.h5', compile=False, custom_objects=custom_objects)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9acf3df8-72be-4226-9ee5-7864d0f77914",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# optimizer = tfa.optimizers.AdamW(weight_decay=0.02, learning_rate=3e-4, epsilon=1e-6, clipvalue=1.5)\n",
    "optimizer = AdamWeightDecay(learning_rate=3e-4, weight_decay_rate=0.2, epsilon=1e-6, clipvalue=1.5)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss={\n",
    "        # 'players_regression_output': tf.keras.losses.MeanSquaredError(),\n",
    "        # 'l_output': tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        # 'r_output': tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        \n",
    "        'teams_regression_output': tf.keras.losses.MeanSquaredError(),\n",
    "        # 'duration_output': tf.keras.losses.MeanSquaredError(),\n",
    "        'win_output': tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1)\n",
    "    },\n",
    "    loss_weights={\n",
    "        # 'players_regression_output': 1.,\n",
    "        # 'l_output': 0.1,\n",
    "        # 'r_output': 0.1,\n",
    "        \n",
    "        'teams_regression_output': 1.5,\n",
    "        # 'duration_output': 0.25,\n",
    "        'win_output': .0,\n",
    "    },\n",
    "    metrics={\n",
    "        # 'players_regression_output': ['mae', 'mean_absolute_percentage_error', ],\n",
    "        # 'l_output': ['accuracy', ],\n",
    "        # 'r_output': ['accuracy', ],\n",
    "        \n",
    "        'teams_regression_output': ['mae', 'mse', ],\n",
    "        # 'duration_output': ['mae', ],\n",
    "        'win_output': ['accuracy', keras.metrics.AUC(num_thresholds=60, name='auc')],\n",
    "    }, \n",
    ")\n",
    "\n",
    "board_name = datetime.datetime.now().strftime(\"%Y-%m-%d - %H-%M-%S\")\n",
    "log_dir = f\"logs/fit/public/params-{model.count_params()} --- data-{board_name}\"\n",
    "\n",
    "monitor = \"val_teams_regression_output_mse\" # \"val_win_output_auc\" \n",
    "try:\n",
    "    with tf.device('/gpu:0'):\n",
    "        tb = keras.callbacks.TensorBoard(log_dir=log_dir),\n",
    "        es = keras.callbacks.EarlyStopping(monitor=monitor, mode='min', patience=25, restore_best_weights=True),\n",
    "        cc = CustomCheckpoint(board_name, monitor=monitor, mode='min', path='CustomCallbackCheckpoints/')\n",
    "        model.fit(\n",
    "            Xtrain, Ytrain,\n",
    "            validation_data=(Xval, Yval),\n",
    "            callbacks=[lr_schedule, es, tb, cc],\n",
    "            verbose=0,\n",
    "            epochs=10**8,\n",
    "            batch_size=1024*2,\n",
    "            shuffle=True,\n",
    "            # sample_weight=np.arange(0.5, 1, 0.5/len(train_indexes)),\n",
    "        )\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ca4ae844-db4b-4553-9878-6cd935d0eb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "40a22994-c445-4bbb-a0e2-a9b14b07ba97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5349479498619077,\n",
       " 0.551639464160593,\n",
       " 0.6903785296324233,\n",
       " 0.5220897615708275,\n",
       " 0.6431965442764579)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(Ytest[1][:, 0], pred[1][:, 0].round())\n",
    "auc = metrics.roc_auc_score(Ytest[1][:, 0], pred[1][:, 0])\n",
    "log_loss = metrics.log_loss(Ytest[1][:, 0], pred[1][:, 0])\n",
    "precision = metrics.precision_score(Ytest[1][:, 0], pred[1][:, 0].round())\n",
    "recall = metrics.recall_score(Ytest[1][:, 0], pred[1][:, 0].round())\n",
    "\n",
    "accuracy, auc, log_loss, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f11126df-fe2d-4422-b9ba-5ffcd1fdec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_sort(true, pred):\n",
    "    idxs = np.argsort(true)\n",
    "    return true[idxs], pred[idxs]\n",
    "\n",
    "def plot_features(true: np.ndarray, pred: np.ndarray, ncols=6, increase_factor=3, title=''):\n",
    "    imgs_num = len(FEATURES)\n",
    "    nrows = imgs_num//ncols + int(imgs_num%ncols > 0)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(ncols*increase_factor, nrows*increase_factor))\n",
    "    fig.suptitle(title, fontsize=4*increase_factor)\n",
    "\n",
    "    for ax, f, feature in zip(axes.flatten(), range(imgs_num), FEATURES):\n",
    "        t, p = true[:, :, f].flatten(), pred[:, :, f].flatten()\n",
    "        t, p = reg_sort(t, p)\n",
    "        \n",
    "        ax.set_title(feature)\n",
    "        ax.plot(p, label='pred', alpha=0.6)\n",
    "        ax.plot(t, label='true', alpha=1.0)\n",
    "        \n",
    "        ax.legend()\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501607be-2300-48cd-bedf-9a97cf815df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features(Ytest[0], pred[0], ncols=7, increase_factor=5, title='teams regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f3e77ae3-13e9-4f80-a114-fda4ff01b6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138, 16)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_hero[0] = 'SPECIAL TOKEN'\n",
    "heroes_ids = set(h_arr.flatten())\n",
    "ids = np.array([0] + list(heroes_ids))\n",
    "\n",
    "emb_layer = model.get_layer('heroes_embedding')\n",
    "W = emb_layer.get_weights()[0]\n",
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "73064309-de54-4323-9362-18d7fce555af",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('output/embeddings/heroes_embeddings', W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a62a7692-a5da-4d48-b6cb-021682ff7249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0b3744a6-89ed-45c7-a1cd-6e95670e5771",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\royta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tsne = TSNE(\n",
    "    n_components=2, \n",
    "    perplexity=64, \n",
    "    early_exaggeration=12,\n",
    "    learning_rate='auto',\n",
    "    random_state=69,\n",
    "    init='random',\n",
    ")\n",
    "\n",
    "embed = tsne.fit_transform(W[ids])\n",
    "x_, y_ = embed[:, 0], embed[:, 1]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(25, 25))\n",
    "sns.scatterplot(x_, y_, ax=ax)\n",
    "ax.axhline(0, c='black', alpha=0.25)\n",
    "ax.axvline(0, c='black', alpha=0.25)\n",
    "\n",
    "for x, y, i in zip(x_, y_, ids):\n",
    "    ax.text(x-.002, y+.0025, id_to_hero[i])\n",
    "    \n",
    "    \n",
    "fig.savefig('output/embeddings/TSNE_heroes', bbox_inches='tight')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fc577f47-2606-43a0-82a7-7a409a26c7f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\royta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=2, random_state=69)\n",
    "embed = pca.fit_transform(W[ids])\n",
    "x_, y_ = embed[:, 0], embed[:, 1]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(25, 25))\n",
    "sns.scatterplot(x_, y_, ax=ax)\n",
    "ax.axhline(0, c='black', alpha=0.25)\n",
    "ax.axvline(0, c='black', alpha=0.25)\n",
    "\n",
    "for x, y, i in zip(x_, y_, ids):\n",
    "    ax.text(x-.002, y+.0025, id_to_hero[i])\n",
    "    \n",
    "fig.savefig('output/embeddings/PCA_heroes', bbox_inches='tight')\n",
    "plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
